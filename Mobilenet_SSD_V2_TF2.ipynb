{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VJyQm_cLRTHtQlEgD_wdPnNzpQobhBbW",
      "authorship_tag": "ABX9TyOvxI7oJEn5jMk7Vp8qFp1e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargav23/Plant-disease-detection/blob/main/Mobilenet_SSD_V2_TF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vXWlStpvoi_F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PlantDoc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0kKEvT_jAAo",
        "outputId": "d8154fce-ed72-4218-d2d5-63b51a14f7bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PlantDoc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVHbiGRAkMB0",
        "outputId": "2d1eb433-ca55-4a4a-e64b-7b5639df2c69"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "ln: target '/mydrive' is not a directory\n",
            "ls: cannot access '/mydrive': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "x9v1zAURqXLx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# navigate to /models/research folder to compile protos\n",
        "\n",
        "%cd models/research"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1LjCuQRqrbs",
        "outputId": "3c87f431-5424-4be3-c902-e587a61a515f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile protos.\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "9eKYPpXkqwib"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow Object Detection API.\n",
        "\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCpHuSRuqzua",
        "outputId": "629bb4d2-af8c-419a-9282-d43b49293e6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.45.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.6-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.4.0)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.1.21)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696777 sha256=0f9595e2232b190f39b53fb0dc456a9dd88d22e8ec3bea58ce494555ca8c25e9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ndbx8th1/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=cd074b22ed715339ada7275fee87979b6c7ad443cfa13b896a012bc17458e8b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=120ff03188a4eec59be3b51d0409a5e8aa62267f37a7f26d562cfd6bc64d3f03\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=e580a70c0d933fd9352b0ae41bb1d6598fb38b81ea152bb66e0d986e7d766191\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=d1ee9f8b3a26ed60abdc018380b48b4f8be505b7b3c980d3028af64954b14ad0\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built object-detection avro-python3 dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow_io, tensorflow-addons, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, sacrebleu, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "Successfully installed apache-beam-2.45.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.1 fasteners-0.18 hdfs-2.7.0 immutabledict-2.2.3 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.6 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.19.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.30.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "zNW4z1LMsJ0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQmaa0G4sHjk",
        "outputId": "35ea98a5-3001-4681-c987-eb8dfb7a43aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir data"
      ],
      "metadata": {
        "id": "4C60FAAPx7Vh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfoUk3OHyADy",
        "outputId": "42918dad-a181-447e-fb2b-12e8bfb7906d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://universe.roboflow.com/ds/5jM5409eQU?key=SalnpoiGwN\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xIBq__l0mtG",
        "outputId": "284be576-599e-4e45-bb45-79f836e9548e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   896  100   896    0     0   3016      0 --:--:-- --:--:-- --:--:--  3027\n",
            "100 74.9M  100 74.9M    0     0  87.7M      0 --:--:-- --:--:-- --:--:--  173M\n",
            "Archive:  roboflow.zip\n",
            " extracting: train/leaves.tfrecord   \n",
            " extracting: train/leaves_label_map.pbtxt  \n",
            " extracting: test/leaves.tfrecord    \n",
            " extracting: test/leaves_label_map.pbtxt  \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: README.dataset.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaFhjq9qx1Ld",
        "outputId": "d8d485ce-0c4a-4b27-c57d-05f14f5b7446"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3lviU-ryGlX",
        "outputId": "b6ebe9f6-dfd9-4037-cdd2-023721947723"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-17 09:00:41--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.193.128, 2607:f8b0:4001:c0f::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.193.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-02-17 09:00:42 (132 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP__hYx-yNZs",
        "outputId": "ce8cf3b8-f6f7-4c2c-9846-68c9f0b1f934"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /content/data/trained-checkpoint"
      ],
      "metadata": {
        "id": "F41yB9RAscN_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZN71P5RA9or",
        "outputId": "7e0337d4-ff59-4305-e7f9-8d2b30e26115"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace /content/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config with https://github.com/bhargav23/Plant-disease-detection/blob/main/pipeline.config"
      ],
      "metadata": {
        "id": "Lf4FxY6ljTph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "  --pipeline_config_path=/content/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "  --model_dir=/content/data/trained-checkpoint \\\n",
        "  --alsologtostderr"
      ],
      "metadata": {
        "id": "SF5YQUq_uFHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d3de0e-d825-400e-efbe-f4103825273f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-17 09:01:28.665318: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-17 09:01:28.665428: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-17 09:01:28.665447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-17 09:01:33.735256: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0217 09:01:33.805037 139636605171520 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0217 09:01:33.810589 139636605171520 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0217 09:01:33.810745 139636605171520 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0217 09:01:33.854924 139636605171520 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/data/train/leaves.tfrecord']\n",
            "I0217 09:01:33.882548 139636605171520 dataset_builder.py:162] Reading unweighted datasets: ['/content/data/train/leaves.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/data/train/leaves.tfrecord']\n",
            "I0217 09:01:33.882775 139636605171520 dataset_builder.py:79] Reading record datasets for input file: ['/content/data/train/leaves.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0217 09:01:33.882898 139636605171520 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0217 09:01:33.882990 139636605171520 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0217 09:01:33.893351 139636605171520 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0217 09:01:33.926133 139636605171520 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0217 09:01:34.826439 139636605171520 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0217 09:01:40.574381 139636605171520 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0217 09:01:43.068949 139636605171520 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0217 09:01:44.470665 139636605171520 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.614083 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.616718 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.617722 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.618668 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.621935 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.622906 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.623838 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.624750 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.628885 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0217 09:02:34.629780 139636605171520 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0217 09:02:35.784007 139632399795968 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.125s\n",
            "I0217 09:04:28.011101 139636605171520 model_lib_v2.py:705] Step 100 per-step time 1.125s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.8969141,\n",
            " 'Loss/localization_loss': 0.40756258,\n",
            " 'Loss/regularization_loss': 0.15318571,\n",
            " 'Loss/total_loss': 1.4576625,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0217 09:04:28.011533 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.8969141,\n",
            " 'Loss/localization_loss': 0.40756258,\n",
            " 'Loss/regularization_loss': 0.15318571,\n",
            " 'Loss/total_loss': 1.4576625,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.414s\n",
            "I0217 09:05:09.349039 139636605171520 model_lib_v2.py:705] Step 200 per-step time 0.414s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6506846,\n",
            " 'Loss/localization_loss': 0.29300594,\n",
            " 'Loss/regularization_loss': 0.15299493,\n",
            " 'Loss/total_loss': 1.0966854,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0217 09:05:09.349338 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.6506846,\n",
            " 'Loss/localization_loss': 0.29300594,\n",
            " 'Loss/regularization_loss': 0.15299493,\n",
            " 'Loss/total_loss': 1.0966854,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.409s\n",
            "I0217 09:05:50.224419 139636605171520 model_lib_v2.py:705] Step 300 per-step time 0.409s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5973444,\n",
            " 'Loss/localization_loss': 0.24068367,\n",
            " 'Loss/regularization_loss': 0.15274675,\n",
            " 'Loss/total_loss': 0.9907748,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0217 09:05:50.224711 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.5973444,\n",
            " 'Loss/localization_loss': 0.24068367,\n",
            " 'Loss/regularization_loss': 0.15274675,\n",
            " 'Loss/total_loss': 0.9907748,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.410s\n",
            "I0217 09:06:31.261977 139636605171520 model_lib_v2.py:705] Step 400 per-step time 0.410s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.61817575,\n",
            " 'Loss/localization_loss': 0.18911427,\n",
            " 'Loss/regularization_loss': 0.15249267,\n",
            " 'Loss/total_loss': 0.9597827,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0217 09:06:31.262330 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.61817575,\n",
            " 'Loss/localization_loss': 0.18911427,\n",
            " 'Loss/regularization_loss': 0.15249267,\n",
            " 'Loss/total_loss': 0.9597827,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.411s\n",
            "I0217 09:07:12.355124 139636605171520 model_lib_v2.py:705] Step 500 per-step time 0.411s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.55978453,\n",
            " 'Loss/localization_loss': 0.18763383,\n",
            " 'Loss/regularization_loss': 0.15225329,\n",
            " 'Loss/total_loss': 0.8996716,\n",
            " 'learning_rate': 0.053333}\n",
            "I0217 09:07:12.355493 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.55978453,\n",
            " 'Loss/localization_loss': 0.18763383,\n",
            " 'Loss/regularization_loss': 0.15225329,\n",
            " 'Loss/total_loss': 0.8996716,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.411s\n",
            "I0217 09:07:53.499611 139636605171520 model_lib_v2.py:705] Step 600 per-step time 0.411s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.531048,\n",
            " 'Loss/localization_loss': 0.25708,\n",
            " 'Loss/regularization_loss': 0.15205182,\n",
            " 'Loss/total_loss': 0.9401798,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0217 09:07:53.500016 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.531048,\n",
            " 'Loss/localization_loss': 0.25708,\n",
            " 'Loss/regularization_loss': 0.15205182,\n",
            " 'Loss/total_loss': 0.9401798,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.414s\n",
            "I0217 09:08:34.858936 139636605171520 model_lib_v2.py:705] Step 700 per-step time 0.414s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.45722398,\n",
            " 'Loss/localization_loss': 0.22200994,\n",
            " 'Loss/regularization_loss': 0.15187249,\n",
            " 'Loss/total_loss': 0.8311064,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0217 09:08:34.859294 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.45722398,\n",
            " 'Loss/localization_loss': 0.22200994,\n",
            " 'Loss/regularization_loss': 0.15187249,\n",
            " 'Loss/total_loss': 0.8311064,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.410s\n",
            "I0217 09:09:15.897580 139636605171520 model_lib_v2.py:705] Step 800 per-step time 0.410s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4668475,\n",
            " 'Loss/localization_loss': 0.22219522,\n",
            " 'Loss/regularization_loss': 0.15178132,\n",
            " 'Loss/total_loss': 0.84082407,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0217 09:09:15.897931 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.4668475,\n",
            " 'Loss/localization_loss': 0.22219522,\n",
            " 'Loss/regularization_loss': 0.15178132,\n",
            " 'Loss/total_loss': 0.84082407,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.409s\n",
            "I0217 09:09:56.765493 139636605171520 model_lib_v2.py:705] Step 900 per-step time 0.409s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4647093,\n",
            " 'Loss/localization_loss': 0.1937393,\n",
            " 'Loss/regularization_loss': 0.15159655,\n",
            " 'Loss/total_loss': 0.8100451,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0217 09:09:56.765794 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.4647093,\n",
            " 'Loss/localization_loss': 0.1937393,\n",
            " 'Loss/regularization_loss': 0.15159655,\n",
            " 'Loss/total_loss': 0.8100451,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.408s\n",
            "I0217 09:10:37.583834 139636605171520 model_lib_v2.py:705] Step 1000 per-step time 0.408s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4264013,\n",
            " 'Loss/localization_loss': 0.1916537,\n",
            " 'Loss/regularization_loss': 0.15152211,\n",
            " 'Loss/total_loss': 0.7695771,\n",
            " 'learning_rate': 0.08}\n",
            "I0217 09:10:37.584166 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.4264013,\n",
            " 'Loss/localization_loss': 0.1916537,\n",
            " 'Loss/regularization_loss': 0.15152211,\n",
            " 'Loss/total_loss': 0.7695771,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.419s\n",
            "I0217 09:11:19.507534 139636605171520 model_lib_v2.py:705] Step 1100 per-step time 0.419s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.41299072,\n",
            " 'Loss/localization_loss': 0.16542011,\n",
            " 'Loss/regularization_loss': 0.15145081,\n",
            " 'Loss/total_loss': 0.7298617,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0217 09:11:19.507859 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.41299072,\n",
            " 'Loss/localization_loss': 0.16542011,\n",
            " 'Loss/regularization_loss': 0.15145081,\n",
            " 'Loss/total_loss': 0.7298617,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.409s\n",
            "I0217 09:12:00.389793 139636605171520 model_lib_v2.py:705] Step 1200 per-step time 0.409s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.41651267,\n",
            " 'Loss/localization_loss': 0.19621788,\n",
            " 'Loss/regularization_loss': 0.15141061,\n",
            " 'Loss/total_loss': 0.7641412,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0217 09:12:00.390112 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.41651267,\n",
            " 'Loss/localization_loss': 0.19621788,\n",
            " 'Loss/regularization_loss': 0.15141061,\n",
            " 'Loss/total_loss': 0.7641412,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.410s\n",
            "I0217 09:12:41.426843 139636605171520 model_lib_v2.py:705] Step 1300 per-step time 0.410s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3916343,\n",
            " 'Loss/localization_loss': 0.17302182,\n",
            " 'Loss/regularization_loss': 0.15140244,\n",
            " 'Loss/total_loss': 0.7160586,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0217 09:12:41.427243 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.3916343,\n",
            " 'Loss/localization_loss': 0.17302182,\n",
            " 'Loss/regularization_loss': 0.15140244,\n",
            " 'Loss/total_loss': 0.7160586,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.411s\n",
            "I0217 09:13:22.546964 139636605171520 model_lib_v2.py:705] Step 1400 per-step time 0.411s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36725676,\n",
            " 'Loss/localization_loss': 0.1832422,\n",
            " 'Loss/regularization_loss': 0.15144272,\n",
            " 'Loss/total_loss': 0.70194167,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0217 09:13:22.547371 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.36725676,\n",
            " 'Loss/localization_loss': 0.1832422,\n",
            " 'Loss/regularization_loss': 0.15144272,\n",
            " 'Loss/total_loss': 0.70194167,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.410s\n",
            "I0217 09:14:03.509771 139636605171520 model_lib_v2.py:705] Step 1500 per-step time 0.410s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.37579253,\n",
            " 'Loss/localization_loss': 0.14279485,\n",
            " 'Loss/regularization_loss': 0.15151884,\n",
            " 'Loss/total_loss': 0.6701062,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0217 09:14:03.510148 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.37579253,\n",
            " 'Loss/localization_loss': 0.14279485,\n",
            " 'Loss/regularization_loss': 0.15151884,\n",
            " 'Loss/total_loss': 0.6701062,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.408s\n",
            "I0217 09:14:44.346278 139636605171520 model_lib_v2.py:705] Step 1600 per-step time 0.408s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3027838,\n",
            " 'Loss/localization_loss': 0.13413103,\n",
            " 'Loss/regularization_loss': 0.15151809,\n",
            " 'Loss/total_loss': 0.5884329,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0217 09:14:44.346663 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.3027838,\n",
            " 'Loss/localization_loss': 0.13413103,\n",
            " 'Loss/regularization_loss': 0.15151809,\n",
            " 'Loss/total_loss': 0.5884329,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.411s\n",
            "I0217 09:15:25.475789 139636605171520 model_lib_v2.py:705] Step 1700 per-step time 0.411s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3411987,\n",
            " 'Loss/localization_loss': 0.16595249,\n",
            " 'Loss/regularization_loss': 0.1515362,\n",
            " 'Loss/total_loss': 0.65868735,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0217 09:15:25.476307 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.3411987,\n",
            " 'Loss/localization_loss': 0.16595249,\n",
            " 'Loss/regularization_loss': 0.1515362,\n",
            " 'Loss/total_loss': 0.65868735,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.410s\n",
            "I0217 09:16:06.467397 139636605171520 model_lib_v2.py:705] Step 1800 per-step time 0.410s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.33882555,\n",
            " 'Loss/localization_loss': 0.15605244,\n",
            " 'Loss/regularization_loss': 0.15158097,\n",
            " 'Loss/total_loss': 0.646459,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0217 09:16:06.467688 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.33882555,\n",
            " 'Loss/localization_loss': 0.15605244,\n",
            " 'Loss/regularization_loss': 0.15158097,\n",
            " 'Loss/total_loss': 0.646459,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.406s\n",
            "I0217 09:16:47.049868 139636605171520 model_lib_v2.py:705] Step 1900 per-step time 0.406s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3147956,\n",
            " 'Loss/localization_loss': 0.13279147,\n",
            " 'Loss/regularization_loss': 0.15166268,\n",
            " 'Loss/total_loss': 0.5992497,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0217 09:16:47.050167 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.3147956,\n",
            " 'Loss/localization_loss': 0.13279147,\n",
            " 'Loss/regularization_loss': 0.15166268,\n",
            " 'Loss/total_loss': 0.5992497,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.407s\n",
            "I0217 09:17:27.755878 139636605171520 model_lib_v2.py:705] Step 2000 per-step time 0.407s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30321258,\n",
            " 'Loss/localization_loss': 0.11729177,\n",
            " 'Loss/regularization_loss': 0.15171757,\n",
            " 'Loss/total_loss': 0.57222193,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0217 09:17:27.756178 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.30321258,\n",
            " 'Loss/localization_loss': 0.11729177,\n",
            " 'Loss/regularization_loss': 0.15171757,\n",
            " 'Loss/total_loss': 0.57222193,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.419s\n",
            "I0217 09:18:09.632133 139636605171520 model_lib_v2.py:705] Step 2100 per-step time 0.419s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30456665,\n",
            " 'Loss/localization_loss': 0.13929385,\n",
            " 'Loss/regularization_loss': 0.15179886,\n",
            " 'Loss/total_loss': 0.5956594,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0217 09:18:09.632435 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.30456665,\n",
            " 'Loss/localization_loss': 0.13929385,\n",
            " 'Loss/regularization_loss': 0.15179886,\n",
            " 'Loss/total_loss': 0.5956594,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.407s\n",
            "I0217 09:18:50.368834 139636605171520 model_lib_v2.py:705] Step 2200 per-step time 0.407s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30378404,\n",
            " 'Loss/localization_loss': 0.16018824,\n",
            " 'Loss/regularization_loss': 0.15188432,\n",
            " 'Loss/total_loss': 0.6158566,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0217 09:18:50.369204 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.30378404,\n",
            " 'Loss/localization_loss': 0.16018824,\n",
            " 'Loss/regularization_loss': 0.15188432,\n",
            " 'Loss/total_loss': 0.6158566,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.412s\n",
            "I0217 09:19:31.572656 139636605171520 model_lib_v2.py:705] Step 2300 per-step time 0.412s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.29410803,\n",
            " 'Loss/localization_loss': 0.15751785,\n",
            " 'Loss/regularization_loss': 0.15198588,\n",
            " 'Loss/total_loss': 0.60361177,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0217 09:19:31.572969 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.29410803,\n",
            " 'Loss/localization_loss': 0.15751785,\n",
            " 'Loss/regularization_loss': 0.15198588,\n",
            " 'Loss/total_loss': 0.60361177,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.425s\n",
            "I0217 09:20:14.132928 139636605171520 model_lib_v2.py:705] Step 2400 per-step time 0.425s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31942824,\n",
            " 'Loss/localization_loss': 0.15184581,\n",
            " 'Loss/regularization_loss': 0.15205485,\n",
            " 'Loss/total_loss': 0.6233289,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0217 09:20:14.133309 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.31942824,\n",
            " 'Loss/localization_loss': 0.15184581,\n",
            " 'Loss/regularization_loss': 0.15205485,\n",
            " 'Loss/total_loss': 0.6233289,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.446s\n",
            "I0217 09:20:58.708973 139636605171520 model_lib_v2.py:705] Step 2500 per-step time 0.446s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24387638,\n",
            " 'Loss/localization_loss': 0.09960391,\n",
            " 'Loss/regularization_loss': 0.15205804,\n",
            " 'Loss/total_loss': 0.49553832,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0217 09:20:58.709351 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.24387638,\n",
            " 'Loss/localization_loss': 0.09960391,\n",
            " 'Loss/regularization_loss': 0.15205804,\n",
            " 'Loss/total_loss': 0.49553832,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.409s\n",
            "I0217 09:21:39.607187 139636605171520 model_lib_v2.py:705] Step 2600 per-step time 0.409s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25311196,\n",
            " 'Loss/localization_loss': 0.13180451,\n",
            " 'Loss/regularization_loss': 0.1521473,\n",
            " 'Loss/total_loss': 0.5370638,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0217 09:21:39.607825 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.25311196,\n",
            " 'Loss/localization_loss': 0.13180451,\n",
            " 'Loss/regularization_loss': 0.1521473,\n",
            " 'Loss/total_loss': 0.5370638,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.412s\n",
            "I0217 09:22:20.828758 139636605171520 model_lib_v2.py:705] Step 2700 per-step time 0.412s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2572059,\n",
            " 'Loss/localization_loss': 0.1274619,\n",
            " 'Loss/regularization_loss': 0.15219332,\n",
            " 'Loss/total_loss': 0.5368611,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0217 09:22:20.829139 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.2572059,\n",
            " 'Loss/localization_loss': 0.1274619,\n",
            " 'Loss/regularization_loss': 0.15219332,\n",
            " 'Loss/total_loss': 0.5368611,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.431s\n",
            "I0217 09:23:03.949126 139636605171520 model_lib_v2.py:705] Step 2800 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2327138,\n",
            " 'Loss/localization_loss': 0.09338551,\n",
            " 'Loss/regularization_loss': 0.15227447,\n",
            " 'Loss/total_loss': 0.47837377,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0217 09:23:03.949485 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.2327138,\n",
            " 'Loss/localization_loss': 0.09338551,\n",
            " 'Loss/regularization_loss': 0.15227447,\n",
            " 'Loss/total_loss': 0.47837377,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.408s\n",
            "I0217 09:23:44.727246 139636605171520 model_lib_v2.py:705] Step 2900 per-step time 0.408s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2492659,\n",
            " 'Loss/localization_loss': 0.13366844,\n",
            " 'Loss/regularization_loss': 0.15238546,\n",
            " 'Loss/total_loss': 0.5353198,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0217 09:23:44.727746 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.2492659,\n",
            " 'Loss/localization_loss': 0.13366844,\n",
            " 'Loss/regularization_loss': 0.15238546,\n",
            " 'Loss/total_loss': 0.5353198,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.410s\n",
            "I0217 09:24:25.680051 139636605171520 model_lib_v2.py:705] Step 3000 per-step time 0.410s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27398485,\n",
            " 'Loss/localization_loss': 0.15137959,\n",
            " 'Loss/regularization_loss': 0.15234546,\n",
            " 'Loss/total_loss': 0.5777099,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0217 09:24:25.680341 139636605171520 model_lib_v2.py:708] {'Loss/classification_loss': 0.27398485,\n",
            " 'Loss/localization_loss': 0.15137959,\n",
            " 'Loss/regularization_loss': 0.15234546,\n",
            " 'Loss/total_loss': 0.5777099,\n",
            " 'learning_rate': 0.0796716}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /content/data/exported-model"
      ],
      "metadata": {
        "id": "nAiEkt7gIlyU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir=/content/data/trained-checkpoint \\\n",
        "    --pipeline_config_path=/content/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "    --output_directory /content/data/exported-model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbmlXycPyCJf",
        "outputId": "5040f491-67c9-4f8d-dcaa-57160871c006"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-17 09:25:15.724570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-17 09:25:15.724683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-17 09:25:15.724701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-17 09:25:18.603179: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0217 09:25:18.679776 139839223142208 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0217 09:25:18.743205 139839223142208 deprecation.py:623] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2e5008e640>, because it is not built.\n",
            "W0217 09:25:51.493452 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2e5008e640>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2de87ad3a0>, because it is not built.\n",
            "W0217 09:25:51.729995 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2de87ad3a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de82dcd60>, because it is not built.\n",
            "W0217 09:25:51.730206 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de82dcd60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de844a5e0>, because it is not built.\n",
            "W0217 09:25:51.730310 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de844a5e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2df01e8af0>, because it is not built.\n",
            "W0217 09:25:51.730393 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2df01e8af0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01e8160>, because it is not built.\n",
            "W0217 09:25:51.730474 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01e8160>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df01e8760>, because it is not built.\n",
            "W0217 09:25:51.730552 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df01e8760>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2df018dd00>, because it is not built.\n",
            "W0217 09:25:51.730625 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2df018dd00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df0295d30>, because it is not built.\n",
            "W0217 09:25:51.730695 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df0295d30>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0295e20>, because it is not built.\n",
            "W0217 09:25:51.730765 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0295e20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2de87a36a0>, because it is not built.\n",
            "W0217 09:25:51.730835 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f2de87a36a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01ed4c0>, because it is not built.\n",
            "W0217 09:25:51.730925 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01ed4c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df01ed6a0>, because it is not built.\n",
            "W0217 09:25:51.731007 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df01ed6a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8739910>, because it is not built.\n",
            "W0217 09:25:51.731077 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8739910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0483bb0>, because it is not built.\n",
            "W0217 09:25:51.731148 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0483bb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df02730d0>, because it is not built.\n",
            "W0217 09:25:51.731217 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df02730d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0249190>, because it is not built.\n",
            "W0217 09:25:51.731288 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0249190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df0249310>, because it is not built.\n",
            "W0217 09:25:51.731358 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df0249310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df02498e0>, because it is not built.\n",
            "W0217 09:25:51.731429 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df02498e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01435b0>, because it is not built.\n",
            "W0217 09:25:51.731500 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01435b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df01437f0>, because it is not built.\n",
            "W0217 09:25:51.731575 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df01437f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de84f1310>, because it is not built.\n",
            "W0217 09:25:51.731646 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de84f1310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8729820>, because it is not built.\n",
            "W0217 09:25:51.731716 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8729820>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8729d90>, because it is not built.\n",
            "W0217 09:25:51.731785 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8729d90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8729850>, because it is not built.\n",
            "W0217 09:25:51.731867 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8729850>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8729520>, because it is not built.\n",
            "W0217 09:25:51.731940 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8729520>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8729cd0>, because it is not built.\n",
            "W0217 09:25:51.732015 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8729cd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df048feb0>, because it is not built.\n",
            "W0217 09:25:51.732086 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df048feb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8730ac0>, because it is not built.\n",
            "W0217 09:25:51.732156 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8730ac0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8373970>, because it is not built.\n",
            "W0217 09:25:51.732224 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8373970>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de83632b0>, because it is not built.\n",
            "W0217 09:25:51.732294 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de83632b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8363400>, because it is not built.\n",
            "W0217 09:25:51.732379 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8363400>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df03ad070>, because it is not built.\n",
            "W0217 09:25:51.732465 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df03ad070>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01237c0>, because it is not built.\n",
            "W0217 09:25:51.732541 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df01237c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df017bb80>, because it is not built.\n",
            "W0217 09:25:51.732615 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df017bb80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df017b040>, because it is not built.\n",
            "W0217 09:25:51.732688 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df017b040>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0355730>, because it is not built.\n",
            "W0217 09:25:51.732765 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2df0355730>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df0456e20>, because it is not built.\n",
            "W0217 09:25:51.732839 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2df0456e20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de87ab8b0>, because it is not built.\n",
            "W0217 09:25:51.732925 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de87ab8b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8448940>, because it is not built.\n",
            "W0217 09:25:51.733007 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8448940>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8448d00>, because it is not built.\n",
            "W0217 09:25:51.733086 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8448d00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8448760>, because it is not built.\n",
            "W0217 09:25:51.733160 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de8448760>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8448340>, because it is not built.\n",
            "W0217 09:25:51.733234 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de8448340>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de84cfa60>, because it is not built.\n",
            "W0217 09:25:51.786270 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f2de84cfa60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de84cf6a0>, because it is not built.\n",
            "W0217 09:25:51.786484 139839223142208 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f2de84cf6a0>, because it is not built.\n",
            "W0217 09:26:13.316149 139839223142208 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/data/exported-model/saved_model/assets\n",
            "I0217 09:26:21.953400 139839223142208 builder_impl.py:797] Assets written to: /content/data/exported-model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/data/exported-model/pipeline.config\n",
            "I0217 09:26:24.204028 139839223142208 config_util.py:253] Writing pipeline config file to /content/data/exported-model/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the saved_model\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "IMAGE_SIZE = (12, 8) # Output display size as you want\n",
        "import matplotlib.pyplot as plt\n",
        "PATH_TO_SAVED_MODEL=\"/content/data/exported-model/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "print('Done!')\n",
        "\n",
        "#Loading the label_map\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/content/data/train/leaves_label_map.pbtxt\",use_display_name=True)\n",
        "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "image_path = \"/content/applescab-leaf1.jpg\"\n",
        "#print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.4, # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "      agnostic_mode=False)\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qfhHuoOaH8Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z30qgy7rtlOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}